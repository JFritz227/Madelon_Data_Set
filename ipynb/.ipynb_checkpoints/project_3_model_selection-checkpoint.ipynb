{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Initiate Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Project_3_madelon\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [48, 64, 105, 128, 241, 336, 338, 378, 442, 453, 475]\n",
    "informative_features = [28, 48, 64, 105, 128, 153, 241, 281, 318, 336,\n",
    "                        338, 378, 433, 442, 451, 453, 455, 472, 475, 493]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "madelon_train_full = madelon_train\n",
    "train_targets = madelon_train_targets\n",
    "train_df = madelon_train_full[informative_features]\n",
    "train_df['targets'] = train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_val_full = madelon_valid\n",
    "val_targets = madelon_val_target\n",
    "val_df = madelon_val_full[informative_features]\n",
    "val_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier Pipeline with 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a KNeighborsClassifier pipeline with SelectKBest and StandardScaler instances (20 features)\n",
    "\n",
    "knc_pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('skb', SelectKBest()),\n",
    "    ('knc', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "knc_params = {\n",
    "    #'knc__n_neighbors': np.arange(1, 30, 1),\n",
    "    'knc__weights': ['uniform', 'distance'],\n",
    "    #'knc__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    #'skb__k': np.arange(1, 11, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "knc_gs = GridSearchCV(knc_pipeline, \n",
    "                      knc_params,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('skb', SelectKBest(k=10, score_func=<function f_classif at 0x7f3eb2cb7510>)), ('knc', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'knc__weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (20 features) and the train_targets\n",
    "\n",
    "knc_gs.fit(X=train_df, y=train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knc__weights': 'uniform'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "knc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.75], [1.0, 0.79999999999999993])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "knc = add_train_test_score_df(train_df, val_df, KNeighborsClassifier(algorithm = 'auto', \n",
    "                                                                     n_neighbors = 6, \n",
    "                                                                     weights = 'distance'), feats = 20)\n",
    "knc_scaled = add_train_test_score_df(train_df, val_df, KNeighborsClassifier(algorithm = 'auto', \n",
    "                                                                     n_neighbors = 6, \n",
    "                                                                     weights = 'distance'), feats = 20, scaled = True)\n",
    "knc, knc_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier Pipeline with 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a KNeighborsClassifier pipeline with SelectKBest and StandardScaler instances (5 features)\n",
    "\n",
    "knc_pipeline_s5b = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('knc', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "knc_params_s5b = {\n",
    "    #'knc__n_neighbors': np.arange(1, 30, 1),\n",
    "    'knc__weights': ['uniform', 'distance'],\n",
    "    #'knc__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "knc_gs_s5b = GridSearchCV(knc_pipeline_s5b, \n",
    "                      knc_params_s5b,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the SKBest = 5 features from the feature selection notebook to train the model\n",
    "\n",
    "skb_feats = [64, 128, 241, 336, 475]\n",
    "train_skb_df = train_df[skb_feats]\n",
    "\n",
    "val_skb_df = val_df[skb_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('knc', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'knc__weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (SKBest = 5 features) and the train_targets\n",
    "\n",
    "knc_gs_s5b.fit(X=train_skb_df, y=train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knc__weights': 'uniform'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "knc_gs_s5b.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8165"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using SKBest = 5 features\n",
    "\n",
    "knc_gs_s5b.score(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71666666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using SKBest = 5 features\n",
    "\n",
    "knc_gs_s5b.score(val_skb_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_skb_df['targets'] = train_targets\n",
    "val_skb_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.58333333333333337], [1.0, 0.58888888888888891])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "knc_skb = add_train_test_score_df(train_skb_df, val_skb_df, KNeighborsClassifier(algorithm = 'auto', \n",
    "                                                                     n_neighbors = 17, \n",
    "                                                                     weights = 'distance'), feats = 5)\n",
    "knc_skb_scaled = add_train_test_score_df(train_skb_df, val_skb_df, KNeighborsClassifier(algorithm = 'auto', \n",
    "                                                                     n_neighbors = 17, \n",
    "                                                                     weights = 'distance'), feats = 5, scaled = True)\n",
    "knc_skb, knc_skb_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier Pipeline with 5 features (SKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a DecisionTreeClassifier pipeline with SelectKBest and StandardScaler instances (5 features)\n",
    "\n",
    "dtc_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "dtc_params = {\n",
    "    'clf__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    'clf__min_samples_split':np.arange(0.01,1,15),\n",
    "    'clf__criterion':['gini','entropy'],\n",
    "    'clf__max_features':np.arange(.01, 1, 15),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "dtc_gs = GridSearchCV(dtc_pipe, \n",
    "                      dtc_params,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the SKBest = 5 features from the feature selection notebook to train the model\n",
    "\n",
    "skb_feats = [64, 128, 241, 336, 475]\n",
    "train_skb_df = train_df[skb_feats]\n",
    "\n",
    "val_skb_df = val_df[skb_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=42, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, None], 'clf__min_samples_split': array([ 0.01]), 'clf__criterion': ['gini', 'entropy'], 'clf__max_features': array([ 0.01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (SKBest = 5 features) and the train_targets\n",
    "\n",
    "dtc_gs.fit(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 0.01,\n",
       " 'clf__min_samples_split': 0.01}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "dtc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80649999999999999"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using SKBest = 5 features\n",
    "\n",
    "dtc_gs.score(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64166666666666672"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using SKBest = 5 features\n",
    "\n",
    "dtc_gs.score(val_skb_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_skb_df['targets'] = train_targets\n",
    "val_skb_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.58333333333333337], [1.0, 0.5722222222222223])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "dtc_skb = add_train_test_score_df(train_skb_df, val_skb_df, DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 5)\n",
    "dtc_skb_scaled = add_train_test_score_df(train_skb_df, val_skb_df, DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 5,\n",
    "                                                                                     scaled = True)\n",
    "dtc_skb, dtc_skb_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier Pipeline with 5 features (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a DecisionTreeClassifier pipeline with RFE and StandardScaler instances (5 features)\n",
    "\n",
    "\n",
    "dtc_pipe_rfe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "dtc_params_rfe = {\n",
    "    'clf__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    'clf__min_samples_split':np.arange(0.01,1,15),\n",
    "    'clf__criterion':['gini','entropy'],\n",
    "    'clf__max_features':np.arange(.01, 1, 15),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "dtc_gs_rfe = GridSearchCV(dtc_pipe_rfe, \n",
    "                      dtc_params_rfe,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 5 RFE features from the feature selection notebook to train the model\n",
    "\n",
    "rfe_feats = [48, 105, 338, 442, 475]\n",
    "\n",
    "train_rfe_df = train_df[rfe_feats]\n",
    "val_rfe_df = val_df[rfe_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=42, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, None], 'clf__min_samples_split': array([ 0.01]), 'clf__criterion': ['gini', 'entropy'], 'clf__max_features': array([ 0.01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 5 RFE features) and the train_targets\n",
    "\n",
    "dtc_gs_rfe.fit(train_rfe_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'gini',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 0.01,\n",
       " 'clf__min_samples_split': 0.01}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "dtc_gs_rfe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85699999999999998"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 5 RFE features\n",
    "\n",
    "dtc_gs_rfe.score(train_rfe_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71666666666666667"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 5 RFE features\n",
    "\n",
    "dtc_gs_rfe.score(val_rfe_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_rfe_df['targets'] = train_targets\n",
    "val_rfe_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.53333333333333333], [1.0, 0.53888888888888886])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "dtc_rfe = add_train_test_score_df(train_rfe_df, val_rfe_df, DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 5)\n",
    "dtc_rfe_scaled = add_train_test_score_df(train_rfe_df, val_rfe_df, DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 5,\n",
    "                                                                                     scaled = True)\n",
    "dtc_rfe, dtc_rfe_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier Pipeline with 10 features (SFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a DecisionTreeClassifier pipeline with SFM and StandardScaler instances (10 features)\n",
    "\n",
    "dtc_pipe_sfm = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "dtc_params_sfm = {\n",
    "    'clf__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    'clf__min_samples_split':np.arange(0.01,1,15),\n",
    "    'clf__criterion':['gini','entropy'],\n",
    "    'clf__max_features':np.arange(.01, 1, 15),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "dtc_gs_sfm = GridSearchCV(dtc_pipe_sfm, \n",
    "                      dtc_params_sfm,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 10 SFM features from the feature selection notebook to train the model\n",
    "\n",
    "sfm_feats = [28, 48, 105, 153, 338, 378, 442, 451, 453, 475]\n",
    "\n",
    "train_sfm_df = train_df[sfm_feats]\n",
    "val_sfm_df = val_df[sfm_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=42, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, None], 'clf__min_samples_split': array([ 0.01]), 'clf__criterion': ['gini', 'entropy'], 'clf__max_features': array([ 0.01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 10 SFM features) and the train_targets\n",
    "\n",
    "dtc_gs_sfm.fit(train_sfm_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'gini',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 0.01,\n",
       " 'clf__min_samples_split': 0.01}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "dtc_gs_sfm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86450000000000005"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 10 SFM features\n",
    "\n",
    "dtc_gs_sfm.score(train_sfm_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75166666666666671"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 10 SFM features\n",
    "\n",
    "dtc_gs_sfm.score(val_sfm_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_sfm_df['targets'] = train_targets\n",
    "val_sfm_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.57222222222222219], [1.0, 0.62777777777777777])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "dtc_sfm = add_train_test_score_df(train_sfm_df, val_sfm_df, DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 10)\n",
    "dtc_sfm_scaled = add_train_test_score_df(train_sfm_df, val_sfm_df, DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 10,\n",
    "                                                                                     scaled = True)\n",
    "dtc_sfm, dtc_sfm_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier with BaggingClassifier using SKBest = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a DecisionTreeClassifier with a BaggingClassifier pipeline with SKBest and StandardScaler instances (5 features)\n",
    "\n",
    "bag_dtc_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', BaggingClassifier(DecisionTreeClassifier(random_state=42), \n",
    "                              max_samples=.8, \n",
    "                              random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['steps', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__base_estimator__class_weight', 'clf__base_estimator__criterion', 'clf__base_estimator__max_depth', 'clf__base_estimator__max_features', 'clf__base_estimator__max_leaf_nodes', 'clf__base_estimator__min_impurity_split', 'clf__base_estimator__min_samples_leaf', 'clf__base_estimator__min_samples_split', 'clf__base_estimator__min_weight_fraction_leaf', 'clf__base_estimator__presort', 'clf__base_estimator__random_state', 'clf__base_estimator__splitter', 'clf__base_estimator', 'clf__bootstrap', 'clf__bootstrap_features', 'clf__max_features', 'clf__max_samples', 'clf__n_estimators', 'clf__n_jobs', 'clf__oob_score', 'clf__random_state', 'clf__verbose', 'clf__warm_start'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets a list of all possible parameters that can be tested using GridSearchCV\n",
    "\n",
    "bag_dtc_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "bag_dtc_params = {\n",
    "    'clf__base_estimator__criterion': ['gini', 'entropy'],\n",
    "    #'clf__base_estimator__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    #'clf__base_estimator__max_features': np.arange(.01, 1, 15),\n",
    "    #'clf__base_estimator__min_samples_split': np.arange(0.01,1,15),\n",
    "    #'clf__max_features':np.arange(1, 6, 1),\n",
    "    #'clf__n_estimators':np.arange(5, 50, 5)\n",
    "    #[DecisionTreeClassifier(max_depth=md, criterion = ['gini', 'entropy'],\n",
    "                                                  # min_samples_split=np.arange(0.01,1,15),\n",
    "                                                  # max_features=np.arange(0.01, 1, 15),\n",
    "                                                  # random_state=42)\n",
    "                            # for md in [5,7,10,None]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "bag_dtc_gs = GridSearchCV(bag_dtc_pipe, bag_dtc_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 5 SKBest features from the feature selection notebook to train the model\n",
    "\n",
    "skb_feats = [64, 128, 241, 336, 475]\n",
    "train_skb_df = train_df[skb_feats]\n",
    "\n",
    "val_skb_df = val_df[skb_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf...n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__base_estimator__criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 10 SFM features) and the train_targets\n",
    "\n",
    "bag_dtc_gs.fit(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__base_estimator__criterion': 'entropy'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "bag_dtc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95750000000000002"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 5 SKBest features and BaggingClassifier\n",
    "\n",
    "bag_dtc_gs.score(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70999999999999996"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 5 SKBest features and BaggingClassifier\n",
    "\n",
    "bag_dtc_gs.score(val_skb_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_skb_df['targets'] = train_targets\n",
    "val_skb_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.99333333333333329, 0.61111111111111116],\n",
       " [0.99333333333333329, 0.62777777777777777])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model (with BaggingClassifier) using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "bag_dtc_skb = add_train_test_score_df(train_skb_df, val_skb_df, BaggingClassifier(DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), \n",
    "                                                                                n_estimators = 15,\n",
    "                                                                                  max_features = 5,\n",
    "                                                                                  random_state = 42), feats = 5)\n",
    "bag_dtc_skb_scaled = add_train_test_score_df(train_skb_df, val_skb_df, BaggingClassifier(DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), \n",
    "                                                                                n_estimators = 15,\n",
    "                                                                                         max_features = 5,\n",
    "                                                                                        random_state = 42), feats = 5,\n",
    "                                                                                     scaled = True)\n",
    "bag_dtc_skb, bag_dtc_skb_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier with BaggingClassifier using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_dtc_rfe_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', BaggingClassifier(DecisionTreeClassifier(random_state=42), \n",
    "                              max_samples=.8, \n",
    "                              random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_dtc_rfe_params = {\n",
    "    'clf__base_estimator__criterion': ['gini', 'entropy'],\n",
    "    #'clf__base_estimator__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    #'clf__base_estimator__max_features': np.arange(.01, 1, 15),\n",
    "    #'clf__base_estimator__min_samples_split': np.arange(0.01,1,15),\n",
    "    #'clf__max_features':np.arange(1, 6, 1),\n",
    "    #'clf__n_estimators':np.arange(5, 50, 5)\n",
    "    #[DecisionTreeClassifier(max_depth=md, criterion = ['gini', 'entropy'],\n",
    "                                                  # min_samples_split=np.arange(0.01,1,15),\n",
    "                                                  # max_features=np.arange(0.01, 1, 15),\n",
    "                                                  # random_state=42)\n",
    "                            # for md in [5,7,10,None]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_dtc_rfe_gs = GridSearchCV(bag_dtc_rfe_pipe, bag_dtc_rfe_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfe_feats = [48, 105, 338, 442, 475]\n",
    "\n",
    "train_rfe_df = train_df[rfe_feats]\n",
    "val_rfe_df = val_df[rfe_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_dtc_rfe_gs.fit(train_rfe_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_dtc_rfe_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_dtc_rfe_gs.score(train_rfe_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_dtc_rfe_gs.score(val_rfe_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rfe_df['targets'] = train_targets\n",
    "val_rfe_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_dtc_rfe = add_train_test_score_df(train_rfe_df, val_rfe_df, BaggingClassifier(DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), \n",
    "                                                                                n_estimators = 40,\n",
    "                                                                                  max_features = 5,\n",
    "                                                                                  random_state = 42), feats = 5)\n",
    "bag_dtc_rfe_scaled = add_train_test_score_df(train_rfe_df, val_rfe_df, BaggingClassifier(DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), \n",
    "                                                                                n_estimators = 40,\n",
    "                                                                                         max_features = 5,\n",
    "                                                                                        random_state = 42), feats = 5,\n",
    "                                                                                     scaled = True)\n",
    "bag_dtc_rfe, bag_dtc_rfe_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier using 5 features (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, \\\n",
    "                                      RFE, SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rfparams = {\n",
    "    'clf__criterion':['gini', 'entropy'],\n",
    "    #'clf__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, None],\n",
    "    #'clf__n_estimators':[10,50,100,200],\n",
    "    #'clf__max_features':['auto','log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfgs = GridSearchCV(rf_pipe, rfparams, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_rfe_feats = [105, 241, 318, 338, 378]\n",
    "train_rf_rfe = train_df[rf_rfe_feats]\n",
    "val_rf_rfe = val_df[rf_rfe_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfgs.fit(train_rf_rfe, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfgs.score(train_rf_rfe,train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfgs.score(val_rf_rfe,val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rf_rfe['targets'] = train_targets\n",
    "val_rf_rfe['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rfe = add_train_test_score_df(train_rf_rfe, val_rf_rfe, RandomForestClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 'auto',\n",
    "                                                                                  n_estimators = 100,\n",
    "                                                                                random_state = 42), feats = 5)\n",
    "rf_rfe_scaled = add_train_test_score_df(train_rf_rfe, val_rf_rfe, RandomForestClassifier(criterion = 'entropy',\n",
    "                                                                                    max_depth = None,\n",
    "                                                                                    max_features = 'auto',\n",
    "                                                                                    n_estimators = 100,\n",
    "                                                                                    random_state = 42), feats = 5,\n",
    "                                                                                    scaled = True)\n",
    "rf_rfe, rf_rfe_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging using RandomForestClassifier with 5 features (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_rf_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',BaggingClassifier(RandomForestClassifier(criterion = 'entropy',\n",
    "                                                    max_depth = None,\n",
    "                                                    max_features = 'auto',\n",
    "                                                    n_estimators = 100,\n",
    "                                                    random_state = 42), max_samples = .8, random_state=42))\n",
    "])\n",
    "\n",
    "bag_rfparams = {\n",
    "    #'clf__base_estimator__criterion':['gini', 'entropy'],\n",
    "    #'clf__base_estimator__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, None],\n",
    "    #'clf__base_estimator__n_estimators':[10,50,100,200],\n",
    "    #'clf__base_estimator__max_features':['auto','log2'],\n",
    "    'clf__max_features':np.arange(1, 6, 1),\n",
    "    #'clf__n_estimators':np.arange(5, 50, 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_rfgs = GridSearchCV(bag_rf_pipe, bag_rfparams, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_rfe_feats = [105, 241, 318, 338, 378]\n",
    "train_rf_rfe = train_df[rf_rfe_feats]\n",
    "val_rf_rfe = val_df[rf_rfe_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_rfgs.fit(train_rf_rfe, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_rfgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_rfgs.score(train_rf_rfe,train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_rfgs.score(val_rf_rfe,val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rf_rfe['targets'] = train_targets\n",
    "val_rf_rfe['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_rf_rfe = add_train_test_score_df(train_rf_rfe, val_rf_rfe, BaggingClassifier(RandomForestClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 'auto',\n",
    "                                                                                  n_estimators = 100,\n",
    "                                                                                random_state = 42), \n",
    "                                                                                max_features = 5,\n",
    "                                                                                n_estimators = 45,\n",
    "                                                                                 max_samples = 0.8,\n",
    "                                                                                random_state = 42\n",
    "                                                                                ), feats = 5)\n",
    "bag_rf_rfe_scaled = add_train_test_score_df(train_rf_rfe, val_rf_rfe, BaggingClassifier(RandomForestClassifier(criterion = 'entropy',\n",
    "                                                                                    max_depth = None,\n",
    "                                                                                    max_features = 'auto',\n",
    "                                                                                    n_estimators = 100,\n",
    "                                                                                    random_state = 42),\n",
    "                                                                                    max_features = 5,\n",
    "                                                                                    n_estimators = 45,\n",
    "                                                                                        max_samples = 0.8,\n",
    "                                                                                    random_state = 42\n",
    "                                                                                       ), feats = 5,\n",
    "                                                                                    scaled = True)\n",
    "bag_rf_rfe, bag_rf_rfe_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using 5 Feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_feats = [105, 241, 318, 338, 378]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_val_full = pd.read_csv('madelon_valid.txt', sep = ' ', header = None)\n",
    "five_val_targets = pd.read_csv('madelon_valid_targets.txt', sep = ' ', header = None)\n",
    "five_val_df = madelon_val_full[five_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_train_full = pd.read_csv('madelon_train.txt', sep = ' ', header = None)\n",
    "five_train_targets = pd.read_csv('madelon_train_targets.txt', sep = ' ', header = None)\n",
    "five_train_df = madelon_train_full[five_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',RandomForestClassifier(random_state=42,\n",
    "                                  criterion = 'entropy',\n",
    "                                  n_estimators = 341,\n",
    "                                  max_features = 'auto',\n",
    "                                  max_depth = None))\n",
    "])\n",
    "\n",
    "#rfparams = {\n",
    "    #'clf__n_estimators':np.arange(1, 400, 20),\n",
    "    #'clf__max_features':['auto','log2'],\n",
    "    #'clf__criterion':['gini', 'entropy'],\n",
    "#    'clf__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None]\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rfgs = GridSearchCV(rf_pipe, rfparams, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.fit(five_train_df, five_train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.score(five_train_df, five_train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.score(five_val_df,five_val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rfgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_w_targets = five_train_df\n",
    "train_df_w_targets['target'] = five_train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_df_w_targets = five_val_df\n",
    "val_df_w_targets['target'] = five_val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_all = [train_df_w_targets, val_df_w_targets]\n",
    "madelon_df = pd.concat(madelon_all)\n",
    "madelon_df = madelon_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = madelon_df['target']\n",
    "X = madelon_df.drop('target', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame()\n",
    "for train_size in np.arange(0.05, 1, 0.05):\n",
    "    scores_list = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = train_size, random_state = 42)\n",
    "    rf_pipe.fit(X_train, y_train)\n",
    "    train_score = rf_pipe.score(X_train, y_train)\n",
    "    test_score = rf_pipe.score(X_test, y_test)\n",
    "    \n",
    "    scores_list.append(train_score)\n",
    "    scores_list.append(test_score)\n",
    "    \n",
    "    scores_df[train_size] = scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.fit(five_val_df, five_val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.score(five_train_df, five_train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.score(five_val_df, five_val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
