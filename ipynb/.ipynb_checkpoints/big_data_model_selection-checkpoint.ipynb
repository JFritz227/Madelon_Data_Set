{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Project_3_madelon\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twenty_feats_df = pd.read_pickle('data/informative_results_df.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging using RandomForestClassifier with 5 features (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a RandomForestClassifier with BaggingClassifier pipeline with RFE and StandardScaler instances (5 features)\n",
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "bag_rf_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',BaggingClassifier(RandomForestClassifier(criterion = 'entropy',\n",
    "                                                    max_depth = None,\n",
    "                                                    max_features = 'auto',\n",
    "                                                    n_estimators = 100,\n",
    "                                                    random_state = 42), \n",
    "                             max_samples = .8, \n",
    "                             max_features = 5, \n",
    "                             random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 5 RFE features from the feature selection notebook to train the model\n",
    "\n",
    "rf_rfe_feats = ['feat_269', 'feat_308', 'feat_395', 'feat_808', 'feat_920']\n",
    "train_rf_rfe = twenty_feats_df[rf_rfe_feats]\n",
    "\n",
    "train_rf_rfe['target'] = twenty_feats_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rf_rfe_sample0 = train_rf_rfe.sample(n = 20000, random_state = 42)\n",
    "train_rf_rfe_sample1 = train_rf_rfe.sample(n = 20000, random_state = 21)\n",
    "train_rf_rfe_sample2 = train_rf_rfe.sample(n = 20000, random_state = 1)\n",
    "\n",
    "train_rf_rfe_sample0_target = train_rf_rfe_sample0['target']\n",
    "train_rf_rfe_sample1_target = train_rf_rfe_sample1['target']\n",
    "train_rf_rfe_sample2_target = train_rf_rfe_sample2['target']\n",
    "\n",
    "train_rf_rfe_sample0 = train_rf_rfe_sample0.drop('target', 1)\n",
    "train_rf_rfe_sample1 = train_rf_rfe_sample1.drop('target', 1)\n",
    "train_rf_rfe_sample2 = train_rf_rfe_sample2.drop('target', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_rf_rfe_sample0 = train_rf_rfe.sample(n = 5000, random_state = 41)\n",
    "test_rf_rfe_sample1 = train_rf_rfe.sample(n = 5000, random_state = 20)\n",
    "test_rf_rfe_sample2 = train_rf_rfe.sample(n = 5000, random_state = 2)\n",
    "\n",
    "test_rf_rfe_sample0_target = test_rf_rfe_sample0['target']\n",
    "test_rf_rfe_sample1_target = test_rf_rfe_sample1['target']\n",
    "test_rf_rfe_sample2_target = test_rf_rfe_sample2['target']\n",
    "\n",
    "test_rf_rfe_sample0 = test_rf_rfe_sample0.drop('target', 1)\n",
    "test_rf_rfe_sample1 = test_rf_rfe_sample1.drop('target', 1)\n",
    "test_rf_rfe_sample2 = test_rf_rfe_sample2.drop('target', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e...n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 5 RFE features) and the train_targets\n",
    "\n",
    "bag_rf_pipe.fit(train_rf_rfe_sample0, train_rf_rfe_sample0_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96279999999999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 5 RFE features and BaggingClassifier\n",
    "\n",
    "bag_rf_pipe.score(train_rf_rfe_sample0,train_rf_rfe_sample0_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86240000000000006"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 5 RFE features and BaggingClassifier\n",
    "\n",
    "score0 = bag_rf_pipe.score(test_rf_rfe_sample0, test_rf_rfe_sample0_target)\n",
    "score1 = bag_rf_pipe.score(test_rf_rfe_sample1, test_rf_rfe_sample1_target)\n",
    "score2 = bag_rf_pipe.score(test_rf_rfe_sample2, test_rf_rfe_sample2_target)\n",
    "avg_score = (score0+score1+score2)/3\n",
    "avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### RandomForestClassifier with 13 features (found in Union of all feature selection models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',RandomForestClassifier(max_features = 'auto', criterion = 'entropy',\n",
    "                                max_depth = None, random_state=42, n_estimators = 350))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "informative_features = ['feat_257', 'feat_269', 'feat_308', 'feat_341', 'feat_504',\n",
    "       'feat_681', 'feat_701', 'feat_724', 'feat_736', 'feat_769',\n",
    "       'feat_808', 'feat_829', 'feat_920']\n",
    "thirteen_feats = twenty_feats_df[informative_features]\n",
    "\n",
    "thirteen_feats['target'] = twenty_feats_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thirteen_feats_sample0 = thirteen_feats.sample(n = 5000, random_state = 42)\n",
    "thirteen_feats_sample1 = thirteen_feats.sample(n = 5000, random_state = 21)\n",
    "thirteen_feats_sample2 = thirteen_feats.sample(n = 5000, random_state = 1)\n",
    "                                             \n",
    "thirteen_feats_sample0_target = thirteen_feats_sample0['target']\n",
    "thirteen_feats_sample1_target = thirteen_feats_sample1['target']\n",
    "thirteen_feats_sample2_target = thirteen_feats_sample2['target']\n",
    "                                             \n",
    "thirteen_feats_sample0 = thirteen_feats_sample0.drop('target', 1)\n",
    "thirteen_feats_sample1 = thirteen_feats_sample1.drop('target', 1)\n",
    "thirteen_feats_sample2 = thirteen_feats_sample2.drop('target', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_thirteen_feats_sample0 = thirteen_feats.sample(n = 1000, random_state = 41)\n",
    "test_thirteen_feats_sample1 = thirteen_feats.sample(n = 1000, random_state = 20)\n",
    "test_thirteen_feats_sample2 = thirteen_feats.sample(n = 1000, random_state = 2)\n",
    "\n",
    "test_thirteen_feats_sample0_target = test_thirteen_feats_sample0['target']\n",
    "test_thirteen_feats_sample1_target = test_thirteen_feats_sample1['target']\n",
    "test_thirteen_feats_sample2_target = test_thirteen_feats_sample2['target']\n",
    "\n",
    "test_thirteen_feats_sample0 = test_thirteen_feats_sample0.drop('target', 1)\n",
    "test_thirteen_feats_sample1 = test_thirteen_feats_sample1.drop('target', 1)\n",
    "test_thirteen_feats_sample2 = test_thirteen_feats_sample2.drop('target', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=350, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipe.fit(thirteen_feats_sample0, thirteen_feats_sample0_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipe.score(thirteen_feats_sample0, thirteen_feats_sample0_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82033333333333325"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score0 = rf_pipe.score(test_thirteen_feats_sample0, test_thirteen_feats_sample0_target)\n",
    "score1 = rf_pipe.score(test_thirteen_feats_sample1, test_thirteen_feats_sample1_target)\n",
    "score2 = rf_pipe.score(test_thirteen_feats_sample2, test_thirteen_feats_sample2_target)\n",
    "avg_score = (score0+score1+score2)/3\n",
    "avg_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
