{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Initiate Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Project_3_madelon\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [48, 64, 105, 128, 241, 336, 338, 378, 442, 453, 475]\n",
    "informative_features = [28, 48, 64, 105, 128, 153, 241, 281, 318, 336,\n",
    "                        338, 378, 433, 442, 451, 453, 455, 472, 475, 493]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_train_full = madelon_train\n",
    "train_targets = madelon_train_targets\n",
    "train_df = madelon_train_full[informative_features]\n",
    "train_df['targets'] = train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_val_full = madelon_valid\n",
    "val_targets = madelon_val_target\n",
    "val_df = madelon_val_full[informative_features]\n",
    "val_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier Pipeline with 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a KNeighborsClassifier pipeline with SelectKBest and StandardScaler instances (20 features)\n",
    "\n",
    "knc_pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('skb', SelectKBest()),\n",
    "    ('knc', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "knc_params = {\n",
    "    #'knc__n_neighbors': np.arange(1, 30, 1),\n",
    "    'knc__weights': ['uniform', 'distance'],\n",
    "    #'knc__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    #'skb__k': np.arange(1, 11, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "knc_gs = GridSearchCV(knc_pipeline, \n",
    "                      knc_params,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('skb', SelectKBest(k=10, score_func=<function f_classif at 0x7f1591ab4510>)), ('knc', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'knc__weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (20 features) and the train_targets\n",
    "\n",
    "knc_gs.fit(X=train_df, y=train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knc__weights': 'uniform'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "knc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.75], [1.0, 0.79999999999999993])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "knc = add_train_test_score_df(train_df, val_df, KNeighborsClassifier(algorithm = 'auto', \n",
    "                                                                     n_neighbors = 6, \n",
    "                                                                     weights = 'distance'), feats = 20)\n",
    "knc_scaled = add_train_test_score_df(train_df, val_df, KNeighborsClassifier(algorithm = 'auto', \n",
    "                                                                     n_neighbors = 6, \n",
    "                                                                     weights = 'distance'), feats = 20, scaled = True)\n",
    "knc, knc_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier Pipeline with 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a KNeighborsClassifier pipeline with SelectKBest and StandardScaler instances (5 features)\n",
    "\n",
    "knc_pipeline_s5b = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('knc', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "knc_params_s5b = {\n",
    "    #'knc__n_neighbors': np.arange(1, 30, 1),\n",
    "    'knc__weights': ['uniform', 'distance'],\n",
    "    #'knc__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "knc_gs_s5b = GridSearchCV(knc_pipeline_s5b, \n",
    "                      knc_params_s5b,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the SKBest = 5 features from the feature selection notebook to train the model\n",
    "\n",
    "skb_feats = [64, 128, 241, 336, 475]\n",
    "train_skb_df = train_df[skb_feats]\n",
    "\n",
    "val_skb_df = val_df[skb_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('knc', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'knc__weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (SKBest = 5 features) and the train_targets\n",
    "\n",
    "knc_gs_s5b.fit(X=train_skb_df, y=train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knc__weights': 'uniform'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "knc_gs_s5b.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using SKBest = 5 features\n",
    "\n",
    "knc_gs_s5b.score(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71666666666666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using SKBest = 5 features\n",
    "\n",
    "knc_gs_s5b.score(val_skb_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_skb_df['targets'] = train_targets\n",
    "val_skb_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.58333333333333337], [1.0, 0.58888888888888891])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "knc_skb = add_train_test_score_df(train_skb_df, val_skb_df, KNeighborsClassifier(algorithm = 'auto', \n",
    "                                                                     n_neighbors = 17, \n",
    "                                                                     weights = 'distance'), feats = 5)\n",
    "knc_skb_scaled = add_train_test_score_df(train_skb_df, val_skb_df, KNeighborsClassifier(algorithm = 'auto', \n",
    "                                                                     n_neighbors = 17, \n",
    "                                                                     weights = 'distance'), feats = 5, scaled = True)\n",
    "knc_skb, knc_skb_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier Pipeline with 5 features (SKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a DecisionTreeClassifier pipeline with SelectKBest and StandardScaler instances (5 features)\n",
    "\n",
    "dtc_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "dtc_params = {\n",
    "    'clf__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    'clf__min_samples_split':np.arange(0.01,1,15),\n",
    "    'clf__criterion':['gini','entropy'],\n",
    "    'clf__max_features':np.arange(.01, 1, 15),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "dtc_gs = GridSearchCV(dtc_pipe, \n",
    "                      dtc_params,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the SKBest = 5 features from the feature selection notebook to train the model\n",
    "\n",
    "skb_feats = [64, 128, 241, 336, 475]\n",
    "train_skb_df = train_df[skb_feats]\n",
    "\n",
    "val_skb_df = val_df[skb_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=42, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, None], 'clf__min_samples_split': array([ 0.01]), 'clf__criterion': ['gini', 'entropy'], 'clf__max_features': array([ 0.01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (SKBest = 5 features) and the train_targets\n",
    "\n",
    "dtc_gs.fit(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 0.01,\n",
       " 'clf__min_samples_split': 0.01}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "dtc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80649999999999999"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using SKBest = 5 features\n",
    "\n",
    "dtc_gs.score(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64166666666666672"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using SKBest = 5 features\n",
    "\n",
    "dtc_gs.score(val_skb_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_skb_df['targets'] = train_targets\n",
    "val_skb_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.58333333333333337], [1.0, 0.5722222222222223])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "dtc_skb = add_train_test_score_df(train_skb_df, val_skb_df, DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 5)\n",
    "dtc_skb_scaled = add_train_test_score_df(train_skb_df, val_skb_df, DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 5,\n",
    "                                                                                     scaled = True)\n",
    "dtc_skb, dtc_skb_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier Pipeline with 5 features (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a DecisionTreeClassifier pipeline with RFE and StandardScaler instances (5 features)\n",
    "\n",
    "\n",
    "dtc_pipe_rfe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "dtc_params_rfe = {\n",
    "    'clf__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    'clf__min_samples_split':np.arange(0.01,1,15),\n",
    "    'clf__criterion':['gini','entropy'],\n",
    "    'clf__max_features':np.arange(.01, 1, 15),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "dtc_gs_rfe = GridSearchCV(dtc_pipe_rfe, \n",
    "                      dtc_params_rfe,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 5 RFE features from the feature selection notebook to train the model\n",
    "\n",
    "rfe_feats = [48, 105, 338, 442, 475]\n",
    "\n",
    "train_rfe_df = train_df[rfe_feats]\n",
    "val_rfe_df = val_df[rfe_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=42, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, None], 'clf__min_samples_split': array([ 0.01]), 'clf__criterion': ['gini', 'entropy'], 'clf__max_features': array([ 0.01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 5 RFE features) and the train_targets\n",
    "\n",
    "dtc_gs_rfe.fit(train_rfe_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'gini',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 0.01,\n",
       " 'clf__min_samples_split': 0.01}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "dtc_gs_rfe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85699999999999998"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 5 RFE features\n",
    "\n",
    "dtc_gs_rfe.score(train_rfe_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71666666666666667"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 5 RFE features\n",
    "\n",
    "dtc_gs_rfe.score(val_rfe_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_rfe_df['targets'] = train_targets\n",
    "val_rfe_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.53333333333333333], [1.0, 0.53888888888888886])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "dtc_rfe = add_train_test_score_df(train_rfe_df, val_rfe_df, DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 5)\n",
    "dtc_rfe_scaled = add_train_test_score_df(train_rfe_df, val_rfe_df, DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 5,\n",
    "                                                                                     scaled = True)\n",
    "dtc_rfe, dtc_rfe_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier Pipeline with 10 features (SFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a DecisionTreeClassifier pipeline with SFM and StandardScaler instances (10 features)\n",
    "\n",
    "dtc_pipe_sfm = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "dtc_params_sfm = {\n",
    "    'clf__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    'clf__min_samples_split':np.arange(0.01,1,15),\n",
    "    'clf__criterion':['gini','entropy'],\n",
    "    'clf__max_features':np.arange(.01, 1, 15),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "dtc_gs_sfm = GridSearchCV(dtc_pipe_sfm, \n",
    "                      dtc_params_sfm,\n",
    "                      cv=5,\n",
    "                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 10 SFM features from the feature selection notebook to train the model\n",
    "\n",
    "sfm_feats = [28, 48, 105, 153, 338, 378, 442, 451, 453, 475]\n",
    "\n",
    "train_sfm_df = train_df[sfm_feats]\n",
    "val_sfm_df = val_df[sfm_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=42, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, None], 'clf__min_samples_split': array([ 0.01]), 'clf__criterion': ['gini', 'entropy'], 'clf__max_features': array([ 0.01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 10 SFM features) and the train_targets\n",
    "\n",
    "dtc_gs_sfm.fit(train_sfm_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'gini',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 0.01,\n",
       " 'clf__min_samples_split': 0.01}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "dtc_gs_sfm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86450000000000005"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 10 SFM features\n",
    "\n",
    "dtc_gs_sfm.score(train_sfm_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75166666666666671"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 10 SFM features\n",
    "\n",
    "dtc_gs_sfm.score(val_sfm_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_sfm_df['targets'] = train_targets\n",
    "val_sfm_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.57222222222222219], [1.0, 0.62777777777777777])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "dtc_sfm = add_train_test_score_df(train_sfm_df, val_sfm_df, DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 10)\n",
    "dtc_sfm_scaled = add_train_test_score_df(train_sfm_df, val_sfm_df, DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), feats = 10,\n",
    "                                                                                     scaled = True)\n",
    "dtc_sfm, dtc_sfm_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier with BaggingClassifier using SKBest = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a DecisionTreeClassifier with a BaggingClassifier pipeline with SKBest and StandardScaler instances (5 features)\n",
    "\n",
    "bag_dtc_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', BaggingClassifier(DecisionTreeClassifier(random_state=42), \n",
    "                              max_samples=.8, \n",
    "                              random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['steps', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__base_estimator__class_weight', 'clf__base_estimator__criterion', 'clf__base_estimator__max_depth', 'clf__base_estimator__max_features', 'clf__base_estimator__max_leaf_nodes', 'clf__base_estimator__min_impurity_split', 'clf__base_estimator__min_samples_leaf', 'clf__base_estimator__min_samples_split', 'clf__base_estimator__min_weight_fraction_leaf', 'clf__base_estimator__presort', 'clf__base_estimator__random_state', 'clf__base_estimator__splitter', 'clf__base_estimator', 'clf__bootstrap', 'clf__bootstrap_features', 'clf__max_features', 'clf__max_samples', 'clf__n_estimators', 'clf__n_jobs', 'clf__oob_score', 'clf__random_state', 'clf__verbose', 'clf__warm_start'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets a list of all possible parameters that can be tested using GridSearchCV\n",
    "\n",
    "bag_dtc_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "bag_dtc_params = {\n",
    "    'clf__base_estimator__criterion': ['gini', 'entropy'],\n",
    "    #'clf__base_estimator__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    #'clf__base_estimator__max_features': np.arange(.01, 1, 15),\n",
    "    #'clf__base_estimator__min_samples_split': np.arange(0.01,1,15),\n",
    "    #'clf__max_features':np.arange(1, 6, 1),\n",
    "    #'clf__n_estimators':np.arange(5, 50, 5)\n",
    "    #[DecisionTreeClassifier(max_depth=md, criterion = ['gini', 'entropy'],\n",
    "                                                  # min_samples_split=np.arange(0.01,1,15),\n",
    "                                                  # max_features=np.arange(0.01, 1, 15),\n",
    "                                                  # random_state=42)\n",
    "                            # for md in [5,7,10,None]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "bag_dtc_gs = GridSearchCV(bag_dtc_pipe, bag_dtc_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 5 SKBest features from the feature selection notebook to train the model\n",
    "\n",
    "skb_feats = [64, 128, 241, 336, 475]\n",
    "train_skb_df = train_df[skb_feats]\n",
    "\n",
    "val_skb_df = val_df[skb_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf...n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__base_estimator__criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 10 SFM features) and the train_targets\n",
    "\n",
    "bag_dtc_gs.fit(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__base_estimator__criterion': 'entropy'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "bag_dtc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95750000000000002"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 5 SKBest features and BaggingClassifier\n",
    "\n",
    "bag_dtc_gs.score(train_skb_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70999999999999996"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 5 SKBest features and BaggingClassifier\n",
    "\n",
    "bag_dtc_gs.score(val_skb_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_skb_df['targets'] = train_targets\n",
    "val_skb_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.99333333333333329, 0.61111111111111116],\n",
       " [0.99333333333333329, 0.62777777777777777])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model (with BaggingClassifier) using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "bag_dtc_skb = add_train_test_score_df(train_skb_df, val_skb_df, BaggingClassifier(DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), \n",
    "                                                                                n_estimators = 15,\n",
    "                                                                                  max_features = 5,\n",
    "                                                                                  random_state = 42), feats = 5)\n",
    "bag_dtc_skb_scaled = add_train_test_score_df(train_skb_df, val_skb_df, BaggingClassifier(DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), \n",
    "                                                                                n_estimators = 15,\n",
    "                                                                                         max_features = 5,\n",
    "                                                                                        random_state = 42), feats = 5,\n",
    "                                                                                     scaled = True)\n",
    "bag_dtc_skb, bag_dtc_skb_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier with BaggingClassifier using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a DecisionTreeClassifier with a BaggingClassifier pipeline with RFE and StandardScaler instances (5 features)\n",
    "\n",
    "bag_dtc_rfe_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', BaggingClassifier(DecisionTreeClassifier(random_state=42), \n",
    "                              max_samples=.8, \n",
    "                              random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "bag_dtc_rfe_params = {\n",
    "    'clf__base_estimator__criterion': ['gini', 'entropy'],\n",
    "    #'clf__base_estimator__max_depth': [1,2,3,4,5,6,7,8,None],\n",
    "    #'clf__base_estimator__max_features': np.arange(.01, 1, 15),\n",
    "    #'clf__base_estimator__min_samples_split': np.arange(0.01,1,15),\n",
    "    #'clf__max_features':np.arange(1, 6, 1),\n",
    "    #'clf__n_estimators':np.arange(5, 50, 5)\n",
    "    #[DecisionTreeClassifier(max_depth=md, criterion = ['gini', 'entropy'],\n",
    "                                                  # min_samples_split=np.arange(0.01,1,15),\n",
    "                                                  # max_features=np.arange(0.01, 1, 15),\n",
    "                                                  # random_state=42)\n",
    "                            # for md in [5,7,10,None]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "bag_dtc_rfe_gs = GridSearchCV(bag_dtc_rfe_pipe, bag_dtc_rfe_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 5 RFE features from the feature selection notebook to train the model\n",
    "\n",
    "rfe_feats = [48, 105, 338, 442, 475]\n",
    "\n",
    "train_rfe_df = train_df[rfe_feats]\n",
    "val_rfe_df = val_df[rfe_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf...n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__base_estimator__criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 5 RFE features) and the train_targets\n",
    "\n",
    "bag_dtc_rfe_gs.fit(train_rfe_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__base_estimator__criterion': 'gini'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "bag_dtc_rfe_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97499999999999998"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 5 RFE features and BaggingClassifier\n",
    "\n",
    "bag_dtc_rfe_gs.score(train_rfe_df, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84166666666666667"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 5 RFE features and BaggingClassifier\n",
    "\n",
    "bag_dtc_rfe_gs.score(val_rfe_df, val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_rfe_df['targets'] = train_targets\n",
    "val_rfe_df['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.7055555555555556], [1.0, 0.71111111111111114])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model (with BaggingClassifier) using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "bag_dtc_rfe = add_train_test_score_df(train_rfe_df, val_rfe_df, BaggingClassifier(DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), \n",
    "                                                                                n_estimators = 40,\n",
    "                                                                                  max_features = 5,\n",
    "                                                                                  random_state = 42), feats = 5)\n",
    "bag_dtc_rfe_scaled = add_train_test_score_df(train_rfe_df, val_rfe_df, BaggingClassifier(DecisionTreeClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 0.01,\n",
    "                                                                                  min_samples_split = 0.01,\n",
    "                                                                                  random_state = 42), \n",
    "                                                                                n_estimators = 40,\n",
    "                                                                                         max_features = 5,\n",
    "                                                                                        random_state = 42), feats = 5,\n",
    "                                                                                     scaled = True)\n",
    "bag_dtc_rfe, bag_dtc_rfe_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier using 5 features (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a RandomForestClassifier pipeline with RFE and StandardScaler instances (5 features)\n",
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rfparams = {\n",
    "    'clf__criterion':['gini', 'entropy'],\n",
    "    #'clf__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, None],\n",
    "    #'clf__n_estimators':[10,50,100,200],\n",
    "    #'clf__max_features':['auto','log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "rfgs = GridSearchCV(rf_pipe, rfparams, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 5 RFE features from the feature selection notebook to train the model\n",
    "\n",
    "rf_rfe_feats = [105, 241, 318, 338, 378]\n",
    "train_rf_rfe = train_df[rf_rfe_feats]\n",
    "val_rf_rfe = val_df[rf_rfe_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 5 RFE features) and the train_targets\n",
    "\n",
    "rfgs.fit(train_rf_rfe, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "rfgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99150000000000005"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 5 RFE features\n",
    "\n",
    "rfgs.score(train_rf_rfe,train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84333333333333338"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 5 RFE features\n",
    "\n",
    "rfgs.score(val_rf_rfe,val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_rf_rfe['targets'] = train_targets\n",
    "val_rf_rfe['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.67222222222222217], [1.0, 0.65555555555555545])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "rf_rfe = add_train_test_score_df(train_rf_rfe, val_rf_rfe, RandomForestClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 'auto',\n",
    "                                                                                  n_estimators = 100,\n",
    "                                                                                random_state = 42), feats = 5)\n",
    "rf_rfe_scaled = add_train_test_score_df(train_rf_rfe, val_rf_rfe, RandomForestClassifier(criterion = 'entropy',\n",
    "                                                                                    max_depth = None,\n",
    "                                                                                    max_features = 'auto',\n",
    "                                                                                    n_estimators = 100,\n",
    "                                                                                    random_state = 42), feats = 5,\n",
    "                                                                                    scaled = True)\n",
    "rf_rfe, rf_rfe_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging using RandomForestClassifier with 5 features (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a RandomForestClassifier with BaggingClassifier pipeline with RFE and StandardScaler instances (5 features)\n",
    "# checks parameters and returns the best parameters for each one listed below. Note: some parameters are commented out \n",
    "# for compiling time reasons. I did run all of these commented out codes at least one time through and the optimal \n",
    "# parameters are used in the function that follows where only 10% of the dataset is used.\n",
    "\n",
    "bag_rf_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',BaggingClassifier(RandomForestClassifier(criterion = 'entropy',\n",
    "                                                    max_depth = None,\n",
    "                                                    max_features = 'auto',\n",
    "                                                    n_estimators = 100,\n",
    "                                                    random_state = 42), max_samples = .8, random_state=42))\n",
    "])\n",
    "\n",
    "bag_rfparams = {\n",
    "    #'clf__base_estimator__criterion':['gini', 'entropy'],\n",
    "    #'clf__base_estimator__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, None],\n",
    "    #'clf__base_estimator__n_estimators':[10,50,100,200],\n",
    "    #'clf__base_estimator__max_features':['auto','log2'],\n",
    "    'clf__max_features':np.arange(1, 6, 1),\n",
    "    #'clf__n_estimators':np.arange(5, 50, 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a GridSearchCV instance to search for the optimal parameters for this model\n",
    "\n",
    "bag_rfgs = GridSearchCV(bag_rf_pipe, bag_rfparams, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses only the top 5 RFE features from the feature selection notebook to train the model\n",
    "\n",
    "rf_rfe_feats = [105, 241, 318, 338, 378]\n",
    "train_rf_rfe = train_df[rf_rfe_feats]\n",
    "val_rf_rfe = val_df[rf_rfe_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e...n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__max_features': array([1, 2, 3, 4, 5])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model using the train_df (top 5 RFE features) and the train_targets\n",
    "\n",
    "bag_rfgs.fit(train_rf_rfe, train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_features': 5}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets best parameters (used in the function call below)\n",
    "\n",
    "bag_rfgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97150000000000003"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns train score for entire dataset (2000 observations) using top 5 RFE features and BaggingClassifier\n",
    "\n",
    "bag_rfgs.score(train_rf_rfe,train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85333333333333339"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns validation score for entire dataset (600 observations) using top 5 RFE features and BaggingClassifier\n",
    "\n",
    "bag_rfgs.score(val_rf_rfe,val_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds the targets to the data set so it is in the correct format for the created function\n",
    "\n",
    "train_rf_rfe['targets'] = train_targets\n",
    "val_rf_rfe['targets'] = val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.97999999999999998, 0.66666666666666663],\n",
       " [0.97999999999999998, 0.65555555555555556])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model (with BaggingClassifier) using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "bag_rf_rfe = add_train_test_score_df(train_rf_rfe, val_rf_rfe, BaggingClassifier(RandomForestClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 'auto',\n",
    "                                                                                  n_estimators = 100,\n",
    "                                                                                random_state = 42), \n",
    "                                                                                max_features = 5,\n",
    "                                                                                n_estimators = 45,\n",
    "                                                                                 max_samples = 0.8,\n",
    "                                                                                random_state = 42\n",
    "                                                                                ), feats = 5)\n",
    "bag_rf_rfe_scaled = add_train_test_score_df(train_rf_rfe, val_rf_rfe, BaggingClassifier(RandomForestClassifier(criterion = 'entropy',\n",
    "                                                                                    max_depth = None,\n",
    "                                                                                    max_features = 'auto',\n",
    "                                                                                    n_estimators = 100,\n",
    "                                                                                    random_state = 42),\n",
    "                                                                                    max_features = 5,\n",
    "                                                                                    n_estimators = 45,\n",
    "                                                                                        max_samples = 0.8,\n",
    "                                                                                    random_state = 42\n",
    "                                                                                       ), feats = 5,\n",
    "                                                                                    scaled = True)\n",
    "bag_rf_rfe, bag_rf_rfe_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier with 11 features (after Further Exploration section in Feature Selection notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eleven_feats = [48, 64, 105, 128, 241, 336, 338, 378, 442, 453, 475]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleven_val_df = madelon_valid[eleven_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eleven_train_df = madelon_train[eleven_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf',RandomForestClassifier(random_state=42, n_estimators = 350))\n",
    "])\n",
    "\n",
    "rfparams = {\n",
    "    'clf__max_features':['auto','log2'],\n",
    "    'clf__criterion':['gini', 'entropy'],\n",
    "    'clf__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfgs = GridSearchCV(rf_pipe, rfparams, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=350, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__max_features': ['auto', 'log2'], 'clf__criterion': ['gini', 'entropy'], 'clf__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs.fit(eleven_train_df, madelon_train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy',\n",
       " 'clf__max_depth': None,\n",
       " 'clf__max_features': 'auto'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs.score(eleven_train_df, madelon_train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfgs.score(eleven_val_df,madelon_val_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48</th>\n",
       "      <th>64</th>\n",
       "      <th>105</th>\n",
       "      <th>128</th>\n",
       "      <th>241</th>\n",
       "      <th>336</th>\n",
       "      <th>338</th>\n",
       "      <th>378</th>\n",
       "      <th>442</th>\n",
       "      <th>453</th>\n",
       "      <th>475</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>440</td>\n",
       "      <td>648</td>\n",
       "      <td>181</td>\n",
       "      <td>452</td>\n",
       "      <td>434</td>\n",
       "      <td>658</td>\n",
       "      <td>628</td>\n",
       "      <td>419</td>\n",
       "      <td>568</td>\n",
       "      <td>471</td>\n",
       "      <td>401</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499</td>\n",
       "      <td>488</td>\n",
       "      <td>431</td>\n",
       "      <td>473</td>\n",
       "      <td>551</td>\n",
       "      <td>469</td>\n",
       "      <td>528</td>\n",
       "      <td>526</td>\n",
       "      <td>463</td>\n",
       "      <td>311</td>\n",
       "      <td>549</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>460</td>\n",
       "      <td>485</td>\n",
       "      <td>593</td>\n",
       "      <td>487</td>\n",
       "      <td>474</td>\n",
       "      <td>465</td>\n",
       "      <td>431</td>\n",
       "      <td>464</td>\n",
       "      <td>503</td>\n",
       "      <td>606</td>\n",
       "      <td>454</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>529</td>\n",
       "      <td>415</td>\n",
       "      <td>698</td>\n",
       "      <td>493</td>\n",
       "      <td>569</td>\n",
       "      <td>398</td>\n",
       "      <td>377</td>\n",
       "      <td>553</td>\n",
       "      <td>447</td>\n",
       "      <td>545</td>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>429</td>\n",
       "      <td>387</td>\n",
       "      <td>451</td>\n",
       "      <td>475</td>\n",
       "      <td>538</td>\n",
       "      <td>385</td>\n",
       "      <td>509</td>\n",
       "      <td>424</td>\n",
       "      <td>536</td>\n",
       "      <td>426</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>464</td>\n",
       "      <td>348</td>\n",
       "      <td>667</td>\n",
       "      <td>493</td>\n",
       "      <td>545</td>\n",
       "      <td>316</td>\n",
       "      <td>429</td>\n",
       "      <td>468</td>\n",
       "      <td>445</td>\n",
       "      <td>428</td>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>447</td>\n",
       "      <td>496</td>\n",
       "      <td>571</td>\n",
       "      <td>485</td>\n",
       "      <td>418</td>\n",
       "      <td>476</td>\n",
       "      <td>538</td>\n",
       "      <td>444</td>\n",
       "      <td>578</td>\n",
       "      <td>657</td>\n",
       "      <td>389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>496</td>\n",
       "      <td>384</td>\n",
       "      <td>584</td>\n",
       "      <td>484</td>\n",
       "      <td>590</td>\n",
       "      <td>372</td>\n",
       "      <td>437</td>\n",
       "      <td>516</td>\n",
       "      <td>401</td>\n",
       "      <td>388</td>\n",
       "      <td>609</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>524</td>\n",
       "      <td>421</td>\n",
       "      <td>700</td>\n",
       "      <td>497</td>\n",
       "      <td>535</td>\n",
       "      <td>396</td>\n",
       "      <td>355</td>\n",
       "      <td>532</td>\n",
       "      <td>432</td>\n",
       "      <td>597</td>\n",
       "      <td>541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>557</td>\n",
       "      <td>628</td>\n",
       "      <td>580</td>\n",
       "      <td>489</td>\n",
       "      <td>464</td>\n",
       "      <td>640</td>\n",
       "      <td>407</td>\n",
       "      <td>590</td>\n",
       "      <td>351</td>\n",
       "      <td>543</td>\n",
       "      <td>433</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>490</td>\n",
       "      <td>619</td>\n",
       "      <td>380</td>\n",
       "      <td>470</td>\n",
       "      <td>449</td>\n",
       "      <td>656</td>\n",
       "      <td>532</td>\n",
       "      <td>500</td>\n",
       "      <td>451</td>\n",
       "      <td>476</td>\n",
       "      <td>413</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>518</td>\n",
       "      <td>492</td>\n",
       "      <td>519</td>\n",
       "      <td>481</td>\n",
       "      <td>476</td>\n",
       "      <td>472</td>\n",
       "      <td>556</td>\n",
       "      <td>539</td>\n",
       "      <td>621</td>\n",
       "      <td>578</td>\n",
       "      <td>456</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>503</td>\n",
       "      <td>570</td>\n",
       "      <td>469</td>\n",
       "      <td>476</td>\n",
       "      <td>422</td>\n",
       "      <td>558</td>\n",
       "      <td>594</td>\n",
       "      <td>517</td>\n",
       "      <td>659</td>\n",
       "      <td>661</td>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>417</td>\n",
       "      <td>438</td>\n",
       "      <td>498</td>\n",
       "      <td>479</td>\n",
       "      <td>488</td>\n",
       "      <td>420</td>\n",
       "      <td>462</td>\n",
       "      <td>410</td>\n",
       "      <td>571</td>\n",
       "      <td>616</td>\n",
       "      <td>471</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>537</td>\n",
       "      <td>504</td>\n",
       "      <td>710</td>\n",
       "      <td>495</td>\n",
       "      <td>476</td>\n",
       "      <td>486</td>\n",
       "      <td>428</td>\n",
       "      <td>586</td>\n",
       "      <td>466</td>\n",
       "      <td>600</td>\n",
       "      <td>455</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>421</td>\n",
       "      <td>502</td>\n",
       "      <td>430</td>\n",
       "      <td>473</td>\n",
       "      <td>465</td>\n",
       "      <td>490</td>\n",
       "      <td>484</td>\n",
       "      <td>414</td>\n",
       "      <td>611</td>\n",
       "      <td>701</td>\n",
       "      <td>445</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>442</td>\n",
       "      <td>450</td>\n",
       "      <td>408</td>\n",
       "      <td>471</td>\n",
       "      <td>551</td>\n",
       "      <td>422</td>\n",
       "      <td>509</td>\n",
       "      <td>432</td>\n",
       "      <td>393</td>\n",
       "      <td>235</td>\n",
       "      <td>544</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>546</td>\n",
       "      <td>744</td>\n",
       "      <td>401</td>\n",
       "      <td>469</td>\n",
       "      <td>435</td>\n",
       "      <td>742</td>\n",
       "      <td>533</td>\n",
       "      <td>576</td>\n",
       "      <td>444</td>\n",
       "      <td>522</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>646</td>\n",
       "      <td>359</td>\n",
       "      <td>464</td>\n",
       "      <td>439</td>\n",
       "      <td>637</td>\n",
       "      <td>507</td>\n",
       "      <td>455</td>\n",
       "      <td>548</td>\n",
       "      <td>623</td>\n",
       "      <td>399</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>468</td>\n",
       "      <td>331</td>\n",
       "      <td>667</td>\n",
       "      <td>492</td>\n",
       "      <td>575</td>\n",
       "      <td>320</td>\n",
       "      <td>439</td>\n",
       "      <td>474</td>\n",
       "      <td>444</td>\n",
       "      <td>356</td>\n",
       "      <td>597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>452</td>\n",
       "      <td>315</td>\n",
       "      <td>522</td>\n",
       "      <td>481</td>\n",
       "      <td>603</td>\n",
       "      <td>287</td>\n",
       "      <td>500</td>\n",
       "      <td>453</td>\n",
       "      <td>523</td>\n",
       "      <td>327</td>\n",
       "      <td>638</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>493</td>\n",
       "      <td>592</td>\n",
       "      <td>511</td>\n",
       "      <td>480</td>\n",
       "      <td>365</td>\n",
       "      <td>585</td>\n",
       "      <td>629</td>\n",
       "      <td>506</td>\n",
       "      <td>647</td>\n",
       "      <td>620</td>\n",
       "      <td>322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>426</td>\n",
       "      <td>608</td>\n",
       "      <td>331</td>\n",
       "      <td>462</td>\n",
       "      <td>446</td>\n",
       "      <td>594</td>\n",
       "      <td>577</td>\n",
       "      <td>410</td>\n",
       "      <td>490</td>\n",
       "      <td>443</td>\n",
       "      <td>403</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>439</td>\n",
       "      <td>376</td>\n",
       "      <td>523</td>\n",
       "      <td>481</td>\n",
       "      <td>538</td>\n",
       "      <td>352</td>\n",
       "      <td>504</td>\n",
       "      <td>437</td>\n",
       "      <td>489</td>\n",
       "      <td>368</td>\n",
       "      <td>544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>424</td>\n",
       "      <td>479</td>\n",
       "      <td>443</td>\n",
       "      <td>474</td>\n",
       "      <td>477</td>\n",
       "      <td>458</td>\n",
       "      <td>512</td>\n",
       "      <td>425</td>\n",
       "      <td>581</td>\n",
       "      <td>570</td>\n",
       "      <td>457</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>431</td>\n",
       "      <td>439</td>\n",
       "      <td>503</td>\n",
       "      <td>479</td>\n",
       "      <td>490</td>\n",
       "      <td>434</td>\n",
       "      <td>461</td>\n",
       "      <td>415</td>\n",
       "      <td>565</td>\n",
       "      <td>620</td>\n",
       "      <td>472</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>484</td>\n",
       "      <td>564</td>\n",
       "      <td>440</td>\n",
       "      <td>474</td>\n",
       "      <td>415</td>\n",
       "      <td>553</td>\n",
       "      <td>613</td>\n",
       "      <td>495</td>\n",
       "      <td>664</td>\n",
       "      <td>596</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>522</td>\n",
       "      <td>321</td>\n",
       "      <td>605</td>\n",
       "      <td>487</td>\n",
       "      <td>611</td>\n",
       "      <td>277</td>\n",
       "      <td>522</td>\n",
       "      <td>549</td>\n",
       "      <td>533</td>\n",
       "      <td>332</td>\n",
       "      <td>651</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>568</td>\n",
       "      <td>749</td>\n",
       "      <td>365</td>\n",
       "      <td>467</td>\n",
       "      <td>441</td>\n",
       "      <td>753</td>\n",
       "      <td>544</td>\n",
       "      <td>618</td>\n",
       "      <td>487</td>\n",
       "      <td>541</td>\n",
       "      <td>421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>514</td>\n",
       "      <td>527</td>\n",
       "      <td>457</td>\n",
       "      <td>475</td>\n",
       "      <td>442</td>\n",
       "      <td>521</td>\n",
       "      <td>615</td>\n",
       "      <td>538</td>\n",
       "      <td>666</td>\n",
       "      <td>537</td>\n",
       "      <td>401</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>447</td>\n",
       "      <td>503</td>\n",
       "      <td>403</td>\n",
       "      <td>470</td>\n",
       "      <td>440</td>\n",
       "      <td>490</td>\n",
       "      <td>626</td>\n",
       "      <td>450</td>\n",
       "      <td>647</td>\n",
       "      <td>526</td>\n",
       "      <td>410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>446</td>\n",
       "      <td>413</td>\n",
       "      <td>524</td>\n",
       "      <td>481</td>\n",
       "      <td>502</td>\n",
       "      <td>384</td>\n",
       "      <td>526</td>\n",
       "      <td>448</td>\n",
       "      <td>603</td>\n",
       "      <td>551</td>\n",
       "      <td>490</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>564</td>\n",
       "      <td>600</td>\n",
       "      <td>547</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>607</td>\n",
       "      <td>460</td>\n",
       "      <td>620</td>\n",
       "      <td>405</td>\n",
       "      <td>503</td>\n",
       "      <td>479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>514</td>\n",
       "      <td>503</td>\n",
       "      <td>515</td>\n",
       "      <td>480</td>\n",
       "      <td>555</td>\n",
       "      <td>485</td>\n",
       "      <td>395</td>\n",
       "      <td>528</td>\n",
       "      <td>467</td>\n",
       "      <td>549</td>\n",
       "      <td>569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>450</td>\n",
       "      <td>544</td>\n",
       "      <td>369</td>\n",
       "      <td>467</td>\n",
       "      <td>523</td>\n",
       "      <td>535</td>\n",
       "      <td>447</td>\n",
       "      <td>451</td>\n",
       "      <td>463</td>\n",
       "      <td>494</td>\n",
       "      <td>510</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>513</td>\n",
       "      <td>515</td>\n",
       "      <td>472</td>\n",
       "      <td>476</td>\n",
       "      <td>550</td>\n",
       "      <td>497</td>\n",
       "      <td>442</td>\n",
       "      <td>525</td>\n",
       "      <td>460</td>\n",
       "      <td>483</td>\n",
       "      <td>556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>441</td>\n",
       "      <td>469</td>\n",
       "      <td>518</td>\n",
       "      <td>481</td>\n",
       "      <td>453</td>\n",
       "      <td>447</td>\n",
       "      <td>579</td>\n",
       "      <td>441</td>\n",
       "      <td>542</td>\n",
       "      <td>482</td>\n",
       "      <td>418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>585</td>\n",
       "      <td>503</td>\n",
       "      <td>683</td>\n",
       "      <td>496</td>\n",
       "      <td>490</td>\n",
       "      <td>482</td>\n",
       "      <td>446</td>\n",
       "      <td>618</td>\n",
       "      <td>553</td>\n",
       "      <td>685</td>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>469</td>\n",
       "      <td>640</td>\n",
       "      <td>397</td>\n",
       "      <td>470</td>\n",
       "      <td>433</td>\n",
       "      <td>655</td>\n",
       "      <td>511</td>\n",
       "      <td>474</td>\n",
       "      <td>562</td>\n",
       "      <td>693</td>\n",
       "      <td>380</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>481</td>\n",
       "      <td>528</td>\n",
       "      <td>511</td>\n",
       "      <td>480</td>\n",
       "      <td>449</td>\n",
       "      <td>516</td>\n",
       "      <td>481</td>\n",
       "      <td>486</td>\n",
       "      <td>640</td>\n",
       "      <td>758</td>\n",
       "      <td>417</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>445</td>\n",
       "      <td>568</td>\n",
       "      <td>230</td>\n",
       "      <td>458</td>\n",
       "      <td>451</td>\n",
       "      <td>566</td>\n",
       "      <td>691</td>\n",
       "      <td>443</td>\n",
       "      <td>606</td>\n",
       "      <td>409</td>\n",
       "      <td>410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>404</td>\n",
       "      <td>416</td>\n",
       "      <td>310</td>\n",
       "      <td>463</td>\n",
       "      <td>585</td>\n",
       "      <td>370</td>\n",
       "      <td>530</td>\n",
       "      <td>392</td>\n",
       "      <td>458</td>\n",
       "      <td>284</td>\n",
       "      <td>618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>474</td>\n",
       "      <td>576</td>\n",
       "      <td>421</td>\n",
       "      <td>472</td>\n",
       "      <td>455</td>\n",
       "      <td>556</td>\n",
       "      <td>544</td>\n",
       "      <td>482</td>\n",
       "      <td>497</td>\n",
       "      <td>466</td>\n",
       "      <td>426</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>430</td>\n",
       "      <td>567</td>\n",
       "      <td>353</td>\n",
       "      <td>465</td>\n",
       "      <td>470</td>\n",
       "      <td>551</td>\n",
       "      <td>525</td>\n",
       "      <td>419</td>\n",
       "      <td>469</td>\n",
       "      <td>449</td>\n",
       "      <td>448</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>404</td>\n",
       "      <td>444</td>\n",
       "      <td>382</td>\n",
       "      <td>469</td>\n",
       "      <td>496</td>\n",
       "      <td>423</td>\n",
       "      <td>568</td>\n",
       "      <td>402</td>\n",
       "      <td>568</td>\n",
       "      <td>421</td>\n",
       "      <td>482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>519</td>\n",
       "      <td>491</td>\n",
       "      <td>577</td>\n",
       "      <td>487</td>\n",
       "      <td>473</td>\n",
       "      <td>474</td>\n",
       "      <td>533</td>\n",
       "      <td>555</td>\n",
       "      <td>587</td>\n",
       "      <td>599</td>\n",
       "      <td>449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>458</td>\n",
       "      <td>408</td>\n",
       "      <td>662</td>\n",
       "      <td>496</td>\n",
       "      <td>498</td>\n",
       "      <td>378</td>\n",
       "      <td>412</td>\n",
       "      <td>458</td>\n",
       "      <td>469</td>\n",
       "      <td>564</td>\n",
       "      <td>483</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>423</td>\n",
       "      <td>487</td>\n",
       "      <td>437</td>\n",
       "      <td>474</td>\n",
       "      <td>520</td>\n",
       "      <td>468</td>\n",
       "      <td>427</td>\n",
       "      <td>408</td>\n",
       "      <td>484</td>\n",
       "      <td>537</td>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>527</td>\n",
       "      <td>621</td>\n",
       "      <td>503</td>\n",
       "      <td>479</td>\n",
       "      <td>460</td>\n",
       "      <td>619</td>\n",
       "      <td>498</td>\n",
       "      <td>554</td>\n",
       "      <td>399</td>\n",
       "      <td>472</td>\n",
       "      <td>431</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>545</td>\n",
       "      <td>513</td>\n",
       "      <td>550</td>\n",
       "      <td>482</td>\n",
       "      <td>483</td>\n",
       "      <td>502</td>\n",
       "      <td>552</td>\n",
       "      <td>615</td>\n",
       "      <td>615</td>\n",
       "      <td>631</td>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>509</td>\n",
       "      <td>589</td>\n",
       "      <td>385</td>\n",
       "      <td>469</td>\n",
       "      <td>450</td>\n",
       "      <td>581</td>\n",
       "      <td>656</td>\n",
       "      <td>536</td>\n",
       "      <td>569</td>\n",
       "      <td>418</td>\n",
       "      <td>426</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>535</td>\n",
       "      <td>484</td>\n",
       "      <td>480</td>\n",
       "      <td>478</td>\n",
       "      <td>553</td>\n",
       "      <td>465</td>\n",
       "      <td>529</td>\n",
       "      <td>551</td>\n",
       "      <td>431</td>\n",
       "      <td>272</td>\n",
       "      <td>562</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>422</td>\n",
       "      <td>637</td>\n",
       "      <td>362</td>\n",
       "      <td>462</td>\n",
       "      <td>434</td>\n",
       "      <td>654</td>\n",
       "      <td>541</td>\n",
       "      <td>424</td>\n",
       "      <td>446</td>\n",
       "      <td>475</td>\n",
       "      <td>394</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>462</td>\n",
       "      <td>508</td>\n",
       "      <td>493</td>\n",
       "      <td>478</td>\n",
       "      <td>463</td>\n",
       "      <td>493</td>\n",
       "      <td>478</td>\n",
       "      <td>465</td>\n",
       "      <td>606</td>\n",
       "      <td>676</td>\n",
       "      <td>437</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>498</td>\n",
       "      <td>598</td>\n",
       "      <td>536</td>\n",
       "      <td>484</td>\n",
       "      <td>414</td>\n",
       "      <td>611</td>\n",
       "      <td>495</td>\n",
       "      <td>515</td>\n",
       "      <td>531</td>\n",
       "      <td>658</td>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>505</td>\n",
       "      <td>482</td>\n",
       "      <td>541</td>\n",
       "      <td>481</td>\n",
       "      <td>535</td>\n",
       "      <td>463</td>\n",
       "      <td>419</td>\n",
       "      <td>528</td>\n",
       "      <td>509</td>\n",
       "      <td>570</td>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>448</td>\n",
       "      <td>311</td>\n",
       "      <td>696</td>\n",
       "      <td>497</td>\n",
       "      <td>590</td>\n",
       "      <td>242</td>\n",
       "      <td>348</td>\n",
       "      <td>430</td>\n",
       "      <td>421</td>\n",
       "      <td>423</td>\n",
       "      <td>601</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>544</td>\n",
       "      <td>540</td>\n",
       "      <td>752</td>\n",
       "      <td>498</td>\n",
       "      <td>463</td>\n",
       "      <td>538</td>\n",
       "      <td>406</td>\n",
       "      <td>582</td>\n",
       "      <td>428</td>\n",
       "      <td>643</td>\n",
       "      <td>437</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>490</td>\n",
       "      <td>543</td>\n",
       "      <td>524</td>\n",
       "      <td>481</td>\n",
       "      <td>443</td>\n",
       "      <td>548</td>\n",
       "      <td>473</td>\n",
       "      <td>507</td>\n",
       "      <td>563</td>\n",
       "      <td>691</td>\n",
       "      <td>387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>431</td>\n",
       "      <td>330</td>\n",
       "      <td>558</td>\n",
       "      <td>484</td>\n",
       "      <td>566</td>\n",
       "      <td>308</td>\n",
       "      <td>458</td>\n",
       "      <td>408</td>\n",
       "      <td>520</td>\n",
       "      <td>448</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       48   64  105  128  241  336  338  378  442  453  475  targets\n",
       "0     440  648  181  452  434  658  628  419  568  471  401       -1\n",
       "1     499  488  431  473  551  469  528  526  463  311  549       -1\n",
       "2     460  485  593  487  474  465  431  464  503  606  454       -1\n",
       "3     529  415  698  493  569  398  377  553  447  545  602        1\n",
       "4     429  387  451  475  538  385  509  424  536  426  560        1\n",
       "5     464  348  667  493  545  316  429  468  445  428  557        1\n",
       "6     447  496  571  485  418  476  538  444  578  657  389        1\n",
       "7     496  384  584  484  590  372  437  516  401  388  609       -1\n",
       "8     524  421  700  497  535  396  355  532  432  597  541        1\n",
       "9     557  628  580  489  464  640  407  590  351  543  433       -1\n",
       "10    490  619  380  470  449  656  532  500  451  476  413       -1\n",
       "11    518  492  519  481  476  472  556  539  621  578  456       -1\n",
       "12    503  570  469  476  422  558  594  517  659  661  383        1\n",
       "13    417  438  498  479  488  420  462  410  571  616  471       -1\n",
       "14    537  504  710  495  476  486  428  586  466  600  455       -1\n",
       "15    421  502  430  473  465  490  484  414  611  701  445       -1\n",
       "16    442  450  408  471  551  422  509  432  393  235  544       -1\n",
       "17    546  744  401  469  435  742  533  576  444  522  392        1\n",
       "18    456  646  359  464  439  637  507  455  548  623  399       -1\n",
       "19    468  331  667  492  575  320  439  474  444  356  597        1\n",
       "20    452  315  522  481  603  287  500  453  523  327  638       -1\n",
       "21    493  592  511  480  365  585  629  506  647  620  322        1\n",
       "22    426  608  331  462  446  594  577  410  490  443  403       -1\n",
       "23    439  376  523  481  538  352  504  437  489  368  544        1\n",
       "24    424  479  443  474  477  458  512  425  581  570  457       -1\n",
       "25    431  439  503  479  490  434  461  415  565  620  472       -1\n",
       "26    484  564  440  474  415  553  613  495  664  596  377        1\n",
       "27    522  321  605  487  611  277  522  549  533  332  651       -1\n",
       "28    568  749  365  467  441  753  544  618  487  541  421        1\n",
       "29    514  527  457  475  442  521  615  538  666  537  401       -1\n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...\n",
       "1970  447  503  403  470  440  490  626  450  647  526  410        1\n",
       "1971  446  413  524  481  502  384  526  448  603  551  490       -1\n",
       "1972  564  600  547  483  492  607  460  620  405  503  479        1\n",
       "1973  514  503  515  480  555  485  395  528  467  549  569        1\n",
       "1974  450  544  369  467  523  535  447  451  463  494  510       -1\n",
       "1975  513  515  472  476  550  497  442  525  460  483  556        1\n",
       "1976  441  469  518  481  453  447  579  441  542  482  418        1\n",
       "1977  585  503  683  496  490  482  446  618  553  685  477        1\n",
       "1978  469  640  397  470  433  655  511  474  562  693  380       -1\n",
       "1979  481  528  511  480  449  516  481  486  640  758  417       -1\n",
       "1980  445  568  230  458  451  566  691  443  606  409  410        1\n",
       "1981  404  416  310  463  585  370  530  392  458  284  618        1\n",
       "1982  474  576  421  472  455  556  544  482  497  466  426       -1\n",
       "1983  430  567  353  465  470  551  525  419  469  449  448       -1\n",
       "1984  404  444  382  469  496  423  568  402  568  421  482        1\n",
       "1985  519  491  577  487  473  474  533  555  587  599  449        1\n",
       "1986  458  408  662  496  498  378  412  458  469  564  483       -1\n",
       "1987  423  487  437  474  520  468  427  408  484  537  513        1\n",
       "1988  527  621  503  479  460  619  498  554  399  472  431       -1\n",
       "1989  545  513  550  482  483  502  552  615  615  631  462        1\n",
       "1990  509  589  385  469  450  581  656  536  569  418  426       -1\n",
       "1991  535  484  480  478  553  465  529  551  431  272  562       -1\n",
       "1992  422  637  362  462  434  654  541  424  446  475  394       -1\n",
       "1993  462  508  493  478  463  493  478  465  606  676  437       -1\n",
       "1994  498  598  536  484  414  611  495  515  531  658  368        1\n",
       "1995  505  482  541  481  535  463  419  528  509  570  538        1\n",
       "1996  448  311  696  497  590  242  348  430  421  423  601       -1\n",
       "1997  544  540  752  498  463  538  406  582  428  643  437       -1\n",
       "1998  490  543  524  481  443  548  473  507  563  691  387        1\n",
       "1999  431  330  558  484  566  308  458  408  520  448  560        1\n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eleven_train_df['targets'] = madelon_train_targets\n",
    "eleven_val_df['targets'] = madelon_val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 0.68333333333333324], [1.0, 0.67222222222222217])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the train score and test score for both raw and scaled data for this particular model (with BaggingClassifier) using only 10% of the dataset samples 3 times.\n",
    "# 200 train observations, 60 validation observations sampled 3 separate times\n",
    "\n",
    "eleven_rf_rfe = add_train_test_score_df(eleven_train_df, eleven_val_df, RandomForestClassifier(criterion = 'entropy',\n",
    "                                                                                  max_depth = None,\n",
    "                                                                                  max_features = 'auto',\n",
    "                                                                                  n_estimators = 350,\n",
    "                                                                                random_state = 42),\n",
    "                                       feats = 11)\n",
    "eleven_rf_rfe_scaled = add_train_test_score_df(eleven_train_df, eleven_val_df, \n",
    "                                               RandomForestClassifier(criterion = 'entropy', \n",
    "                                                                      max_depth = None, \n",
    "                                                                      max_features = 'auto', \n",
    "                                                                      n_estimators = 350, \n",
    "                                                                      random_state = 42), \n",
    "                                                scaled = True,\n",
    "                                                feats = 11)\n",
    "eleven_rf_rfe, eleven_rf_rfe_scaled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
